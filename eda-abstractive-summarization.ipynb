{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0616 12:08:15.217847 139739548358464 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO) \n",
    "tf.enable_resource_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values used in the base model of transformer were; num_layers=6, d_model = 512, dff = 2048. See the paper for all the other versions of the transformer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0616 12:08:16.332240 139739548358464 <ipython-input-3-cc026df3b2cc>:6] Job Configuration:\n",
      "BATCH_SIZE: 2\n",
      "BUFFER_SIZE: 1\n",
      "CHECKPOINTDIR: checkpoint\n",
      "DROPOUT_RATE: 0.1\n",
      "D_FF: 2048\n",
      "D_MODEL: 768\n",
      "INITIAL_LR: 0.003\n",
      "INPUT_SEQ_LEN: 512\n",
      "LOGDIR: log\n",
      "MAX_EXAMPLE_LEN: null\n",
      "NUM_EPOCHS: 3\n",
      "NUM_HEADS: 8\n",
      "NUM_LAYERS: 8\n",
      "OUTPUT_SEQ_LEN: 75\n",
      "VOCAB_SIZE: 30522\n",
      "WARMUP_STEPS: 4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from config import config\n",
    "\n",
    "\n",
    "BERT_MODEL_URL = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "logging.info('Job Configuration:\\n' + str(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0616 12:08:16.348723 139739548358464 resolver.py:79] Using /tmp/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0616 12:08:17.249488 139739548358464 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0616 12:08:19.532262 139739548358464 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "I0616 12:08:20.572359 139739548358464 abstractive_summarizer.py:52] Extracting pretrained word embeddings weights from BERT\n",
      "I0616 12:08:26.385534 139739548358464 abstractive_summarizer.py:63] Embedding matrix shape '(30522, 768)'\n"
     ]
    }
   ],
   "source": [
    "from models.abstractive_summarizer import AbstractiveSummarization\n",
    "from models.abstractive_summarizer import train\n",
    "from models.abstractive_summarizer import eval\n",
    "\n",
    "\n",
    "    \n",
    "model = AbstractiveSummarization(\n",
    "    num_layers=config.NUM_LAYERS,\n",
    "    d_model=config.D_MODEL,\n",
    "    num_heads=config.NUM_HEADS,\n",
    "    dff=config.D_FF,\n",
    "    vocab_size=config.VOCAB_SIZE,\n",
    "    input_seq_len=config.INPUT_SEQ_LEN,\n",
    "    output_seq_len=config.OUTPUT_SEQ_LEN,\n",
    "    rate=config.DROPOUT_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0616 12:08:26.406254 139739548358464 dataset_builder.py:526] No config specified, defaulting to first: cnn_dailymail/plain_text\n",
      "I0616 12:08:26.407960 139739548358464 dataset_builder.py:174] Overwrite dataset info from restored data version.\n",
      "I0616 12:08:26.411083 139739548358464 dataset_builder.py:216] Reusing dataset cnn_dailymail (/home/ec2-user/tensorflow_datasets/cnn_dailymail/plain_text/0.0.2)\n",
      "I0616 12:08:26.536819 139739548358464 <ipython-input-5-4d53a75058dd>:10] '287113' training examples, '143556' batches\n",
      "I0616 12:08:26.537620 139739548358464 <ipython-input-5-4d53a75058dd>:11] '13368' validation examples, '6684' batches\n",
      "I0616 12:08:26.538442 139739548358464 <ipython-input-5-4d53a75058dd>:12] '11490' testing examples, '5745' batches\n"
     ]
    }
   ],
   "source": [
    "from data.load import load_cnn_dailymail\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, n_train_examples, n_val_examples, n_test_examples = load_cnn_dailymail()\n",
    "\n",
    "n_train_batches = n_train_examples // config.BATCH_SIZE\n",
    "n_val_batches = n_val_examples // config.BATCH_SIZE\n",
    "n_test_batches = n_test_examples // config.BATCH_SIZE\n",
    "\n",
    "logging.info(f\"'{n_train_examples}' training examples, '{n_train_batches}' batches\")\n",
    "logging.info(f\"'{n_val_examples}' validation examples, '{n_val_batches}' batches\")\n",
    "logging.info(f\"'{n_test_examples}' testing examples, '{n_test_batches}' batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.keras.initializers import Constant\n",
    "\n",
    "from tqdm import tqdm\n",
    "from config import config\n",
    "\n",
    "from data.load import load_cnn_dailymail\n",
    "\n",
    "from random import randint\n",
    "from rouge import Rouge\n",
    "\n",
    "from ops.tokenization import tokenizer\n",
    "from ops.tokenization import convert_idx_to_token_tensor\n",
    "\n",
    "from ops.session import initialize_vars\n",
    "from ops.session import save_variable_specs\n",
    "\n",
    "from ops.metrics import calculate_rouge\n",
    "from ops.tensor import with_column\n",
    "from ops.regularization import label_smoothing\n",
    "from ops.optimization import noam_scheme\n",
    "\n",
    "from models.abstractive_summarizer import AbstractiveSummarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvs = tf.trainable_variables()\n",
    "\n",
    "for i in tvs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0616 12:08:26.575592 139739548358464 abstractive_summarizer.py:437] Building Training Graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0616 12:08:29.729345 139739548358464 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "I0616 12:08:29.867604 139739548358464 abstractive_summarizer.py:99] Building:'Draft summary'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0616 12:08:35.134247 139739548358464 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/bert-summarization/models/abstractive_summarizer.py:114: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0616 12:08:38.071396 139739548358464 deprecation.py:323] From /home/ec2-user/SageMaker/bert-summarization/models/abstractive_summarizer.py:114: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "I0616 12:08:38.081864 139739548358464 abstractive_summarizer.py:226] Building: 'Refined Summary'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0616 12:08:38.787830 139739548358464 saver.py:1489] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "x0, x1, x2, y0, y1, y2 = el\n",
    "\n",
    "xs = (x0, x1, x2)\n",
    "ys = (y0, y1, y2)\n",
    "\n",
    "train_loss, train_op, global_step, train_summaries = train(model, xs, ys)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)  \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 512)\n",
      "(2, 512)\n",
      "(2, 512)\n",
      "(2, 76)\n",
      "(2, 76)\n",
      "(2, 76)\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:26:48.006563 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "I0615 19:26:48.143085 139794197460800 abstractive_summarizer.py:123] Building: 'Greedy Draft Summary'\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/bert-summarization/models/abstractive_summarizer.py:157: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0615 19:26:56.669544 139794197460800 deprecation.py:323] From /home/ec2-user/SageMaker/bert-summarization/models/abstractive_summarizer.py:157: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "100%|██████████| 74/74 [03:06<00:00,  2.30s/it]\n",
      "I0615 19:29:54.509504 139794197460800 abstractive_summarizer.py:302] Building: 'Greedy Refined Summary'\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:29:59.034554 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "  1%|▏         | 1/74 [00:07<08:55,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:03.584740 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "  3%|▎         | 2/74 [00:11<07:47,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:08.138754 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "  4%|▍         | 3/74 [00:16<07:00,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:12.747010 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "  5%|▌         | 4/74 [00:21<06:26,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:17.419087 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "  7%|▋         | 5/74 [00:25<06:03,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:22.128870 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "  8%|▊         | 6/74 [00:30<05:47,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:26.881333 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "  9%|▉         | 7/74 [00:35<05:35,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:31.684487 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 11%|█         | 8/74 [00:40<05:26,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:36.521135 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 12%|█▏        | 9/74 [00:44<05:19,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:41.456908 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 14%|█▎        | 10/74 [00:49<05:15,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:46.382058 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 15%|█▍        | 11/74 [00:54<05:10,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:51.363225 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 16%|█▌        | 12/74 [01:03<06:09,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:30:59.745841 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 18%|█▊        | 13/74 [01:08<05:46,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:04.818515 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 19%|█▉        | 14/74 [01:13<05:29,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:09.925565 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 20%|██        | 15/74 [01:18<05:17,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:15.083199 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 22%|██▏       | 16/74 [01:23<05:08,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:20.311517 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 23%|██▎       | 17/74 [01:28<05:01,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:25.553627 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 24%|██▍       | 18/74 [01:34<04:55,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:30.865527 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 26%|██▌       | 19/74 [01:39<04:51,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:36.214194 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 27%|██▋       | 20/74 [01:44<04:46,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:41.649343 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 28%|██▊       | 21/74 [01:50<04:43,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:47.100961 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 30%|██▉       | 22/74 [01:55<04:40,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:52.670351 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 31%|███       | 23/74 [02:01<04:37,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:31:58.263122 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 32%|███▏      | 24/74 [02:06<04:35,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:32:03.988697 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 34%|███▍      | 25/74 [02:12<04:33,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:32:09.739588 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 35%|███▌      | 26/74 [02:22<05:28,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:32:19.588694 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 36%|███▋      | 27/74 [02:28<05:07,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:32:25.405430 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 38%|███▊      | 28/74 [02:34<04:51,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:32:31.294965 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 39%|███▉      | 29/74 [02:39<04:38,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:32:37.212141 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 41%|████      | 30/74 [02:45<04:28,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:32:43.204988 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 42%|████▏     | 31/74 [02:51<04:21,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:32:49.218033 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 43%|████▎     | 32/74 [02:57<04:14,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:32:55.262098 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 45%|████▍     | 33/74 [03:03<04:08,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:01.374086 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 46%|████▌     | 34/74 [03:10<04:03,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:07.580184 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 47%|████▋     | 35/74 [03:16<03:58,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:13.802564 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 49%|████▊     | 36/74 [03:22<03:53,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:20.060233 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 50%|█████     | 37/74 [03:28<03:48,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:26.515850 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 51%|█████▏    | 38/74 [03:35<03:45,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:32.837521 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 53%|█████▎    | 39/74 [03:41<03:40,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:39.245677 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 54%|█████▍    | 40/74 [03:47<03:35,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:45.721845 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 55%|█████▌    | 41/74 [03:54<03:30,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:52.222171 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 57%|█████▋    | 42/74 [04:00<03:25,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:33:58.804740 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 58%|█████▊    | 43/74 [04:12<04:06,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:34:10.347102 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 59%|█████▉    | 44/74 [04:19<03:46,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:34:16.990556 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 61%|██████    | 45/74 [04:25<03:31,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:34:23.711979 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 62%|██████▏   | 46/74 [04:32<03:19,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:34:30.454564 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 64%|██████▎   | 47/74 [04:39<03:09,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:34:37.235438 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 65%|██████▍   | 48/74 [04:46<03:00,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:34:44.060151 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 66%|██████▌   | 49/74 [04:52<02:52,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:34:50.959196 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 68%|██████▊   | 50/74 [04:59<02:45,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:34:57.873987 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 69%|██████▉   | 51/74 [05:06<02:39,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:35:04.908656 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 70%|███████   | 52/74 [05:13<02:32,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:35:11.938001 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 72%|███████▏  | 53/74 [05:20<02:26,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:35:18.971777 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 73%|███████▎  | 54/74 [05:27<02:19,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:35:26.008142 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 74%|███████▍  | 55/74 [05:34<02:13,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:35:33.083797 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 76%|███████▌  | 56/74 [05:41<02:06,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:35:40.236503 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 77%|███████▋  | 57/74 [05:49<02:00,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:35:47.391528 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 78%|███████▊  | 58/74 [05:56<01:53,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:35:54.644374 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 80%|███████▉  | 59/74 [06:03<01:47,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:36:01.922394 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 81%|████████  | 60/74 [06:10<01:40,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:36:09.279062 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 82%|████████▏ | 61/74 [06:18<01:34,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:36:16.625084 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 84%|████████▍ | 62/74 [06:25<01:27,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:36:24.001254 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 85%|████████▌ | 63/74 [06:32<01:20,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:36:31.446330 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 86%|████████▋ | 64/74 [06:40<01:13,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:36:38.975918 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 88%|████████▊ | 65/74 [06:53<01:22,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:36:52.448280 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 89%|████████▉ | 66/74 [07:01<01:09,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:37:00.053670 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 91%|█████████ | 67/74 [07:08<00:58,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:37:07.682067 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 92%|█████████▏| 68/74 [07:16<00:48,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:37:15.314093 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 93%|█████████▎| 69/74 [07:24<00:39,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:37:23.029086 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 95%|█████████▍| 70/74 [07:31<00:31,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:37:30.776597 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 96%|█████████▌| 71/74 [07:39<00:23,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:37:38.559156 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 97%|█████████▋| 72/74 [07:47<00:15,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:37:46.365857 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 99%|█████████▊| 73/74 [07:55<00:07,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 19:37:54.291556 139794197460800 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "100%|██████████| 74/74 [08:03<00:00,  7.87s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-72c69d857d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_refined_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     print()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)  \n",
    "#     tmp = sess.run(el)\n",
    "    x0, x1, x2, y0, y1, y2 = el\n",
    "    \n",
    "    for i in [x0, x1, x2, y0, y1, y2]:\n",
    "        print(sess.run(i).shape)\n",
    "            \n",
    "#     a, b= model((x0,x1,x2))\n",
    "    \n",
    "    logits_draft_summary, preds_draft_summary, draft_attention_dist, logits_refined_summary, preds_refined_summary, refined_attention_dist = model((x0,x1,x2))\n",
    "        \n",
    "    initialize_vars(sess)\n",
    "    \n",
    "    a= sess.run([preds_refined_summary])\n",
    "    print(a.shape)\n",
    "    print(a)\n",
    "#     print()\n",
    "#     print(b.shape)\n",
    "#     print(b) \n",
    "#     print()  \n",
    "#     print(c.shape)\n",
    "#     print(c)     \n",
    "#     print(c.shape, '\\n')\n",
    "#     print(c)     \n",
    "#     print(d.shape, '\\n')\n",
    "#     print(d)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'abstractive_summarization/decoder/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_1:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_1:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_2:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_2:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_3:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_3:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_4:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_4:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_5:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_5:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_6:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_6:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_7:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_7:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_1/kernel:0' shape=(768, 2048) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_1/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_2/kernel:0' shape=(2048, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_2/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_1:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_1:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_2:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_2:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_8:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_8:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_9:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_9:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_10:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_10:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_11:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_11:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_12:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_12:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_13:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_13:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_14:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_14:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_15:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_15:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_11/kernel:0' shape=(768, 2048) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_11/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_12/kernel:0' shape=(2048, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_12/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_3:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_3:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_4:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_4:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_5:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_5:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_16:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_16:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_17:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_17:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_18:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_18:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_19:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_19:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_20:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_20:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_21:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_21:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_22:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_22:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_23:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_23:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_21/kernel:0' shape=(768, 2048) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_21/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_22/kernel:0' shape=(2048, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_22/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_6:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_6:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_7:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_7:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_8:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_8:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_24:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_24:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_25:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_25:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_26:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_26:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_27:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_27:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_28:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_28:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_29:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_29:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_30:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_30:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_31:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_31:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_31/kernel:0' shape=(768, 2048) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_31/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_32/kernel:0' shape=(2048, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_32/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_9:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_9:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_10:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_10:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_11:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_11:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_32:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_32:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_33:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_33:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_34:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_34:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_35:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_35:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_36:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_36:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_37:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_37:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_38:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_38:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_39:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_39:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_41/kernel:0' shape=(768, 2048) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_41/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_42/kernel:0' shape=(2048, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_42/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_12:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_12:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_13:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_13:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_14:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_14:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_40:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_40:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_41:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_41:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_42:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_42:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_43:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_43:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_44:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_44:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_45:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_45:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_46:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_46:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_47:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_47:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_51/kernel:0' shape=(768, 2048) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_51/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_52/kernel:0' shape=(2048, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_52/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_15:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_15:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_16:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_16:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_17:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_17:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_48:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_48:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_49:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_49:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_50:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_50:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_51:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_51:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_52:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_52:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_53:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_53:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_54:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_54:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_55:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_55:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_61/kernel:0' shape=(768, 2048) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_61/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_62/kernel:0' shape=(2048, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_62/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_18:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_18:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_19:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_19:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_20:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_20:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_56:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_56:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_57:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_57:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_58:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_58:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_59:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_59:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_60:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_60:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_61:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_61:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_62:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_62:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/kernel_63:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/bias_63:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_71/kernel:0' shape=(768, 2048) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_71/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_72/kernel:0' shape=(2048, 768) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/dense_72/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_21:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_21:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_22:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_22:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/gamma_23:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/beta_23:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer/layer_normalization/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer/layer_normalization/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer/layer_normalization_1/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer/layer_normalization_1/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer/layer_normalization_2/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer/layer_normalization_2/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_1/layer_normalization_3/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_1/layer_normalization_3/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_1/layer_normalization_4/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_1/layer_normalization_4/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_1/layer_normalization_5/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_1/layer_normalization_5/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_2/layer_normalization_6/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_2/layer_normalization_6/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_2/layer_normalization_7/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_2/layer_normalization_7/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_2/layer_normalization_8/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_2/layer_normalization_8/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_3/layer_normalization_9/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_3/layer_normalization_9/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_3/layer_normalization_10/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_3/layer_normalization_10/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_3/layer_normalization_11/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_3/layer_normalization_11/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_4/layer_normalization_12/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_4/layer_normalization_12/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_4/layer_normalization_13/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_4/layer_normalization_13/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_4/layer_normalization_14/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_4/layer_normalization_14/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_5/layer_normalization_15/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_5/layer_normalization_15/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_5/layer_normalization_16/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_5/layer_normalization_16/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_5/layer_normalization_17/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_5/layer_normalization_17/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_6/layer_normalization_18/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_6/layer_normalization_18/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_6/layer_normalization_19/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_6/layer_normalization_19/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_6/layer_normalization_20/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_6/layer_normalization_20/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_7/layer_normalization_21/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_7/layer_normalization_21/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_7/layer_normalization_22/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_7/layer_normalization_22/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_7/layer_normalization_23/gamma:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/decoder/decoder_layer_7/layer_normalization_23/beta:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/dense/kernel:0' shape=(768, 30522) dtype=float32>\n",
      "<tf.Variable 'abstractive_summarization/dense/bias:0' shape=(30522,) dtype=float32>\n"
     ]
    }
   ],
   "source": [
    "variables = tf.get_default_graph().get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "\n",
    "for i in variables: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0613 19:06:54.430439 139843988014912 <ipython-input-9-ee212edc8049>:449] Building Training Graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0613 19:06:58.338555 139843988014912 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "I0613 19:06:58.502389 139843988014912 <ipython-input-9-ee212edc8049>:112] Building:'Draft summary'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 19:07:03.779280 139843988014912 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-ee212edc8049>:127: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 19:07:06.773543 139843988014912 deprecation.py:323] From <ipython-input-9-ee212edc8049>:127: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "I0613 19:07:06.784623 139843988014912 <ipython-input-9-ee212edc8049>:236] Building: 'Refined Summary'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0613 19:07:07.623564 139843988014912 saver.py:1489] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from rouge import Rouge\n",
    "from ops.session import initialize_vars\n",
    "from ops.session import save_variable_specs\n",
    "\n",
    "\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "train_stream = train_iterator.get_next()\n",
    "\n",
    "# val_iterator = val_dataset.make_initializable_iterator()\n",
    "# val_stream = val_iterator.get_next()\n",
    "\n",
    "xs, ys = train_stream[:3], train_stream[3:]\n",
    "train_loss, train_op, global_step, train_summaries = model.train(xs, ys)\n",
    "\n",
    "# xs, ys = val_stream[:3], val_stream[3:]\n",
    "# y, y_hat, eval_loss, eval_summaries = model.eval(xs, ys)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=config.NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert_layer (BertLayer)       multiple                  110104890 \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        multiple                  23440896  \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  63023104  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  23471418  \n",
      "=================================================================\n",
      "Total params: 220,040,308\n",
      "Trainable params: 86,494,522\n",
      "Non-trainable params: 133,545,786\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0613 19:10:56.591774 139843988014912 <ipython-input-14-76323c486f43>:16] Initializing from scratch\n",
      "I0613 19:11:04.208605 139843988014912 session.py:44] Variables info has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_params:  613275999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0613 19:11:41.390239 139843988014912 <ipython-input-14-76323c486f43>:35] Running Training Job for '114844' steps\n",
      "  0%|          | 38/114845 [05:22<236:57:04,  7.43s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "\n",
    "    if os.path.isdir(config.LOGDIR):\n",
    "        shutil.rmtree(config.LOGDIR)\n",
    "\n",
    "    os.mkdir(config.LOGDIR)\n",
    "\n",
    "    ckpt = tf.train.latest_checkpoint(config.CHECKPOINTDIR)\n",
    "\n",
    "    rouge = Rouge()\n",
    "\n",
    "    if ckpt is None:\n",
    "        logging.info(\"Initializing from scratch\")\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        save_variable_specs(os.path.join(config.LOGDIR, \"specs\"))\n",
    "    else:\n",
    "        saver.restore(sess, ckpt)        \n",
    "\n",
    "    summary_writer_train = tf.summary.FileWriter(os.path.join(config.LOGDIR, 'train'), sess.graph)\n",
    "    summary_writer_eval = tf.summary.FileWriter(os.path.join(config.LOGDIR, 'eval'), sess.graph)\n",
    "\n",
    "\n",
    "    initialize_vars(sess)\n",
    "\n",
    "    _gs = sess.run(global_step)\n",
    "\n",
    "    sess.run(train_iterator.initializer)\n",
    "#     sess.run(val_iterator.initializer)\n",
    "\n",
    "    total_steps = config.NUM_EPOCHS * n_train_batches\n",
    "\n",
    "    logger.info(f\"Running Training Job for '{total_steps}' steps\")\n",
    "    \n",
    "    for i in tqdm(range(_gs, total_steps+1)):\n",
    "\n",
    "        _loss, _, _gs, _summary = sess.run([train_loss, train_op, global_step, train_summaries])\n",
    "\n",
    "        epoch = math.ceil(_gs / n_train_batches)\n",
    "\n",
    "        summary_writer_train.add_summary(_summary, _gs)\n",
    "        summary_writer_train.flush() \n",
    "\n",
    "#         if (_gs and _gs % n_train_batches == 0):\n",
    "\n",
    "#             logger.info(f\"Epoch '{epoch}' done\")\n",
    "#             logger.info(f\"Current training step: '{_gs}\")\n",
    "\n",
    "#             _y, _y_hat, _eval_summary = sess.run([y, y_hat, eval_summaries])\n",
    "\n",
    "#             summary_writer_eval.add_summary(_eval_summary, 0)\n",
    "#             summary_writer_eval.flush()       \n",
    "\n",
    "#             # monitor a random sample\n",
    "#             rnd = randint(0, _y.shape[0] - 1)\n",
    "\n",
    "#             y_rnd = ' '.join(tokenizer.convert_ids_to_tokens(_y[rnd]))\n",
    "#             y_hat_rnd = ' '.join(tokenizer.convert_ids_to_tokens(_y_hat[rnd]))\n",
    "\n",
    "#             rouges = rouge.get_scores(y_rnd, y_hat_rnd)[0]\n",
    "#             r1_val, r2_val, rl_val = rouges['rouge-1'][\"f\"], rouges['rouge-2'][\"f\"], rouges['rouge-l'][\"f\"]\n",
    "\n",
    "#             print('Target:')\n",
    "#             print(y_rnd)\n",
    "#             print('Prediction:')\n",
    "#             print(y_hat_rnd)\n",
    "\n",
    "#             print(f\"ROUGE-1 '{r1_val}'\")\n",
    "#             print(f\"ROUGE-2 '{r2_val}'\")\n",
    "#             print(f\"ROUGE-L '{rl_val}'\")\n",
    "#             print(f\"ROUGE-AVG '{np.mean([r1_val, r2_val, rl_val])}'\", '\\n--\\n')\n",
    "\n",
    "#             logging.info(\"Checkpoint: Saving Model\")\n",
    "\n",
    "#             model_output = f\"abstractive_summarization_2019_epoch_{epoch}_loss_{str(round(_loss, 4))}\"\n",
    "\n",
    "#             ckpt_name = os.path.join(config.CHECKPOINTDIR, model_output)\n",
    "\n",
    "#             saver.save(sess, ckpt_name, global_step=_gs)\n",
    "\n",
    "#             logging.info(f\"After training '{_gs}' steps, '{ckpt_name}' has been saved.\")\n",
    "\n",
    "    summary_writer_train.close()  \n",
    "#     summary_writer_eval.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)  \n",
    "#     tmp = sess.run(el)\n",
    "    x0, x1, x2, y0, y1, y2 = el\n",
    "    \n",
    "    a, b = model((x0,x1,x2), (y0, y1, y2), True)\n",
    "    \n",
    "    initialize_vars(sess)\n",
    "    \n",
    "    a,b = sess.run([a,b])\n",
    "    print(a.shape)\n",
    "    print(a)\n",
    "    print()\n",
    "    print(b.shape)\n",
    "    print(b) \n",
    "    print()\n",
    "#     print(c.shape)\n",
    "#     print(c)     \n",
    "#     print(c.shape, '\\n')\n",
    "#     print(c)     \n",
    "#     print(d.shape, '\\n')\n",
    "#     print(d)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(b'/tmp/tfhub_modules/5a395eafef2a37bd9fc55d7f6ae676d2a134a838/assets/vocab.txt') as f:\n",
    "    data = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0608 01:01:57.134044 139913473955648 <ipython-input-14-9abbb652388f>:377] Building Evaluation Graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0608 01:02:01.785801 139913473955648 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "I0608 01:02:01.973906 139913473955648 <ipython-input-14-9abbb652388f>:98] Building: 'Greedy Draft Summary'\n",
      "100%|██████████| 2/2 [00:10<00:00,  6.23s/it]\n",
      "I0608 01:02:12.164133 139913473955648 <ipython-input-14-9abbb652388f>:196] Building: 'Greedy Refined Summary'\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0608 01:02:13.135066 139913473955648 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0608 01:02:16.977452 139913473955648 saver.py:1489] Saver not created because there are no variables in the graph to restore\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert_layer_1 (BertLayer)     multiple                  110104890 \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      multiple                  23440896  \n",
      "_________________________________________________________________\n",
      "decoder_1 (Decoder)          multiple                  63023104  \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             multiple                  23471418  \n",
      "=================================================================\n",
      "Total params: 220,040,308\n",
      "Trainable params: 86,494,522\n",
      "Non-trainable params: 133,545,786\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[node IteratorGetNext (defined at <ipython-input-11-04a087f227a6>:2) ]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-04a087f227a6>\", line 2, in <module>\n    stream = iterator.get_next()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 414, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1685, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[node IteratorGetNext (defined at <ipython-input-11-04a087f227a6>:2) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[{{node IteratorGetNext}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8b3ac22023ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_eval_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_eval_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[node IteratorGetNext (defined at <ipython-input-11-04a087f227a6>:2) ]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-04a087f227a6>\", line 2, in <module>\n    stream = iterator.get_next()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 414, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1685, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[node IteratorGetNext (defined at <ipython-input-11-04a087f227a6>:2) ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    if os.path.isdir(config.LOGDIR):\n",
    "        shutil.rmtree(config.LOGDIR)\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(config.LOGDIR, sess.graph)\n",
    "        \n",
    "    initialize_vars(sess)\n",
    "    \n",
    "    for i in range(1):\n",
    "        \n",
    "        sess.run(iterator.initializer)\n",
    "        \n",
    "        _y, _y_hat, _eval_summary = sess.run([y, y_hat, eval_summaries])\n",
    "        \n",
    "        summary_writer.add_summary(_eval_summary, 0)\n",
    "        summary_writer.flush()       \n",
    "        \n",
    "        # monitor a random sample\n",
    "        rnd = randint(0, _y.shape[0] - 1)\n",
    "\n",
    "        print('Target:')\n",
    "        print(' '.join(tokenizer.convert_ids_to_tokens(_y[rnd])))\n",
    "        print('Prediction:')\n",
    "        print(' '.join(tokenizer.convert_ids_to_tokens(_y_hat[rnd])))\n",
    "        \n",
    "    summary_writer.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(pred, real):\n",
    "    \"\"\"\n",
    "    Since the target sequences are padded,\n",
    "    it is important to apply a padding mask when calculating the loss.\n",
    "    \"\"\"\n",
    "    logits_draft_summary, logits_refined_summary = pred\n",
    "    \n",
    "    target_ids_ = label_smoothing(tf.one_hot(real, depth=self.vocab_size))\n",
    "\n",
    "    # use right shifted target\n",
    "    loss_draft = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits_draft_summary, labels=target_ids_[:, 1:])\n",
    "\n",
    "    # use non-shifted target (we want to predict the masked word)\n",
    "    loss_refined = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits_refined_summary, labels=target_ids_[:, :-1])\n",
    "\n",
    "    loss = loss_draft + loss_refined    \n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    \n",
    "    loss *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-92394159f759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmax_decode_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seqlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     eos_id=EOS_ID)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# with tf.Session() as sess:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-319b611e4043>\u001b[0m in \u001b[0;36msequence_beam_search\u001b[0;34m(symbols_to_logits_fn, initial_ids, initial_cache, vocab_size, beam_size, alpha, max_decode_length, eos_id)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0meos_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n\u001b[0;32m--> 495\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-319b611e4043>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, initial_ids, initial_cache)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m\"\"\"Beam search for sequences with highest scores.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         finished_state = tf.while_loop(\n",
      "\u001b[0;32m<ipython-input-33-319b611e4043>\u001b[0m in \u001b[0;36m_create_initial_state\u001b[0;34m(self, initial_ids, initial_cache)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0malive_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_expand_to_beam_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0malive_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malive_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Create tensor for storing initial log probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "vocab_size = 30522\n",
    "beam_size = 3\n",
    "alpha = 0.8\n",
    "max_seqlen = 10\n",
    "EOS_ID = 102\n",
    "\n",
    "initial_ids = tf.zeros([batch_size], dtype=tf.int32)\n",
    "\n",
    "decoded_ids, scores = sequence_beam_search(\n",
    "    symbols_to_logits_fn=None,\n",
    "    initial_ids=initial_ids,\n",
    "    initial_cache=None,\n",
    "    vocab_size=vocab_size,\n",
    "    beam_size=beam_size,\n",
    "    alpha=alpha,\n",
    "    max_decode_length=max_seqlen,\n",
    "    eos_id=EOS_ID)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     print(tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_each_timestamp(x, mask_with):\n",
    "    \"\"\"\n",
    "    !!! CURRENTLY NOT USED\n",
    "    \n",
    "    Masks each word in the summary draft one by one with the [MASK] token\n",
    "    At t-th time step the t-th word of input summary is\n",
    "    masked, and the decoder predicts the refined word given other\n",
    "    words of the summary.\n",
    "    \n",
    "    x :: (N, T)\n",
    "    returrn :: (N, T-2, T)\n",
    "    \n",
    "    We do not mask the first and last postition (corresponding to [CLS] and [SEP])\n",
    "    \"\"\"\n",
    "\n",
    "    N, T = tf.shape(x)[0], tf.shape(x)[1]\n",
    "\n",
    "    first = tf.reshape(tf.tile(x[:, 0], [T-2]), [N, T-2, 1])\n",
    "    last = tf.reshape(tf.tile(x[:, -1], [T-2]), [N, T-2, 1])\n",
    "    \n",
    "    x = x[:, 1:-1]\n",
    "    T = T - 2\n",
    "    \n",
    "    masked = tf.reshape(tf.tile(x, [1, T]), [N, T, T])\n",
    "    \n",
    "    diag = tf.ones([N, T], dtype=masked.dtype) * mask_with\n",
    "    masked = tf.linalg.set_diag(masked, diag)\n",
    "    \n",
    "    masked = tf.concat([first, masked, last], axis=2)\n",
    "    \n",
    "    return masked\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    tensor = tf.constant([[1,2,3], [4,5,6], [4,5,6], [4,5,6], [4,5,6]])\n",
    "    \n",
    "    print(sess.run( tf.random_uniform((), 0, tf.shape(tensor)[0], tf.int32)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-935522348baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_accuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m               \u001b[0mweighted_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighted_masked_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m               \u001b[0moutput_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \"\"\"\n\u001b[1;32m    646\u001b[0m     \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m     \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m       \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ecfc6dd94308>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(pred, real)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mimportant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mapply\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0mmask\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mcalculating\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlogits_draft_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_refined_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtarget_ids_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m       raise TypeError(\n\u001b[0;32m--> 442\u001b[0;31m           \u001b[0;34m\"Tensor objects are only iterable when eager execution is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[1;32m    444\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn."
     ]
    }
   ],
   "source": [
    "\n",
    "_gs\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "learning_rate = noam_scheme(initial_lr, global_step, warmup_steps)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.98, epsilon=1e-9)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_function,\n",
    "    metrics=[tf.keras.metrics.categorical_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, tf.keras.Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)  \n",
    "#     tmp = sess.run(el)\n",
    "    x0, x1, x2, y0, y1, y2 = el\n",
    "    \n",
    "    a,b,_,c,d,_ = model((x0,x1,x2))\n",
    "    \n",
    "    initialize_vars(sess)\n",
    "    \n",
    "    a,b,c,d = sess.run([a,b,c,d])\n",
    "    print(a.shape, '\\n')\n",
    "    print(a)\n",
    "    print(b.shape, '\\n')\n",
    "    print(b) \n",
    "    print(c.shape, '\\n')\n",
    "    print(c)     \n",
    "    print(d.shape, '\\n')\n",
    "    print(d)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Adam/iterations:0' shape=() dtype=int64>, <tf.Variable 'Adam/lr:0' shape=() dtype=float32>, <tf.Variable 'Adam/beta_1:0' shape=() dtype=float32>, <tf.Variable 'Adam/beta_2:0' shape=() dtype=float32>, <tf.Variable 'Adam/decay:0' shape=() dtype=float32>, <tf.Variable 'Adam_1/iterations:0' shape=() dtype=int64>, <tf.Variable 'Adam_1/lr:0' shape=() dtype=float32>, <tf.Variable 'Adam_1/beta_1:0' shape=() dtype=float32>, <tf.Variable 'Adam_1/beta_2:0' shape=() dtype=float32>, <tf.Variable 'Adam_1/decay:0' shape=() dtype=float32>, <tf.Variable 'Adam_2/iterations:0' shape=() dtype=int64>, <tf.Variable 'Adam_2/lr:0' shape=() dtype=float32>, <tf.Variable 'Adam_2/beta_1:0' shape=() dtype=float32>, <tf.Variable 'Adam_2/beta_2:0' shape=() dtype=float32>, <tf.Variable 'Adam_2/decay:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.trainable_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 6 arrays: [<tf.Tensor 'IteratorGetNext_1:0' shape=(?, ?) dtype=int64>, <tf.Tensor 'IteratorGetNext_1:1' shape=(?, ?) dtype=int64>, <tf.Tensor 'IteratorGetNext_1:2' shape=(?, ?) dtype=int64>, <tf.Tensor 'Iterato...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-73404c0660db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_initializable_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    321\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    324\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m       raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 6 arrays: [<tf.Tensor 'IteratorGetNext_1:0' shape=(?, ?) dtype=int64>, <tf.Tensor 'IteratorGetNext_1:1' shape=(?, ?) dtype=int64>, <tf.Tensor 'IteratorGetNext_1:2' shape=(?, ?) dtype=int64>, <tf.Tensor 'Iterato..."
     ]
    }
   ],
   "source": [
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "model.fit(el, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3fd9c1e6963b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minitialize_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2237\u001b[0m               \u001b[0;34m'Please provide model inputs as a list or tuple of 2  or 3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m               \u001b[0;34m'elements: (input, target) or (input, target, sample_weights)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2239\u001b[0;31m               'Received %s' % next_element)\n\u001b[0m\u001b[1;32m   2240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    initialize_vars(sess)    \n",
    "    model.fit(train_dataset, epochs=1, steps_per_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?) (?, ?) (?, ?)\n",
      "(?, ?) (?, ?) (?, ?)\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 02:27:36.021267 140483075295040 saver.py:1489] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0602 02:27:37.085570 140483075295040 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-92704cbc1b5f>:90: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0602 02:27:41.069661 140483075295040 deprecation.py:323] From <ipython-input-9-92704cbc1b5f>:90: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 02:27:42.188103 140483075295040 saver.py:1489] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 02:27:45.645426 140483075295040 saver.py:1489] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 02:27:49.526523 140483075295040 saver.py:1489] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 02:27:53.526570 140483075295040 saver.py:1489] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.578041]\n"
     ]
    }
   ],
   "source": [
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)  \n",
    "#     tmp = sess.run(el)\n",
    "    x0, x1, x2, y0, y1, y2 = el\n",
    "    print(x0.shape, x1.shape, x2.shape)\n",
    "    print(y0.shape, y1.shape, y2.shape)\n",
    "    \n",
    "    a = model((x0,x1,x2), (y0,y1,y2), True)\n",
    "    \n",
    "    initialize_vars(sess)\n",
    "#     for i in m.trainable_weights: print(i)\n",
    "#     raise ValueError\n",
    "    \n",
    "    a = sess.run([a])\n",
    "    print(a)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.summary.scalar('lr', lr)\n",
    "# tf.summary.scalar(\"loss\", loss)\n",
    "# tf.summary.scalar(\"global_step\", global_step)\n",
    "\n",
    "# summaries = tf.summary.merge_all()\n",
    "\n",
    "warmup_steps = 4000\n",
    "initial_lr = 0.0003\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = model(inputs, targets)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "\n",
    "def noam_scheme(init_lr, global_step, warmup_steps=4000.):\n",
    "    '''Noam scheme learning rate decay\n",
    "    init_lr: initial learning rate. scalar.\n",
    "    global_step: scalar.\n",
    "    warmup_steps: scalar. During warmup_steps, learning rate increases\n",
    "        until it reaches init_lr.\n",
    "    '''\n",
    "    step = tf.cast(global_step + 1, dtype=tf.float32)\n",
    "    return init_lr * warmup_steps ** 0.5 * tf.minimum(step * warmup_steps ** -1.5, step ** -0.5)\n",
    "\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "learning_rate = noam_scheme(initial_lr, global_step, warmup_steps)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "\n",
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)  \n",
    "#     tmp = sess.run(el)\n",
    "    x0, x1, x2, y0, y1, y2 = el\n",
    "    print(x0.shape, x1.shape, x2.shape)\n",
    "    print(y0.shape, y1.shape, y2.shape)\n",
    "    \n",
    "    loss_value, grads = grad(model, (x0,x1,x2), (y0,y1,y2))\n",
    "    \n",
    "    print(loss_value)\n",
    "    print(grads)\n",
    "\n",
    "    initialize_vars(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_id = tf.keras.layers.Input(shape=(MAX_EXAMPLE_LEN,), name=\"input_ids\")\n",
    "in_mask = tf.keras.layers.Input(shape=(MAX_EXAMPLE_LEN,), name=\"input_masks\")\n",
    "in_segment = tf.keras.layers.Input(shape=(MAX_EXAMPLE_LEN,), name=\"segment_ids\")\n",
    "\n",
    "warmup_steps = 4000\n",
    "initial_lr = 0.0003\n",
    "\n",
    "def noam_scheme(init_lr, global_step, warmup_steps=4000.):\n",
    "    '''Noam scheme learning rate decay\n",
    "    init_lr: initial learning rate. scalar.\n",
    "    global_step: scalar.\n",
    "    warmup_steps: scalar. During warmup_steps, learning rate increases\n",
    "        until it reaches init_lr.\n",
    "    '''\n",
    "    step = tf.cast(global_step + 1, dtype=tf.float32)\n",
    "    return init_lr * warmup_steps ** 0.5 * tf.minimum(step * warmup_steps ** -1.5, step ** -0.5)\n",
    "\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "learning_rate = noam_scheme(initial_lr, global_step, warmup_steps)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0601 17:55:21.698049 140022164780864 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Error while reading resource variable global_step from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/global_step)\n\t [[node global_step/Read/ReadVariableOp (defined at <ipython-input-4-76a7a9e69621>:3) ]]\n\nCaused by op 'global_step/Read/ReadVariableOp', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-76a7a9e69621>\", line 3, in <module>\n    global_step = tf.train.get_or_create_global_step()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/training_util.py\", line 162, in get_or_create_global_step\n    global_step_tensor = create_global_step(graph)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/training_util.py\", line 145, in create_global_step\n    ops.GraphKeys.GLOBAL_STEP])\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2488, in default_variable_creator\n    import_scope=import_scope)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 294, in __init__\n    constraint=constraint)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 446, in _init_from_args\n    value = self._read_variable_op()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 728, in _read_variable_op\n    self._dtype)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 550, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable global_step from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/global_step)\n\t [[node global_step/Read/ReadVariableOp (defined at <ipython-input-4-76a7a9e69621>:3) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable global_step from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/global_step)\n\t [[{{node global_step/Read/ReadVariableOp}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-76a7a9e69621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_gs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable global_step from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/global_step)\n\t [[node global_step/Read/ReadVariableOp (defined at <ipython-input-4-76a7a9e69621>:3) ]]\n\nCaused by op 'global_step/Read/ReadVariableOp', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-76a7a9e69621>\", line 3, in <module>\n    global_step = tf.train.get_or_create_global_step()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/training_util.py\", line 162, in get_or_create_global_step\n    global_step_tensor = create_global_step(graph)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/training_util.py\", line 145, in create_global_step\n    ops.GraphKeys.GLOBAL_STEP])\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2488, in default_variable_creator\n    import_scope=import_scope)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 294, in __init__\n    constraint=constraint)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 446, in _init_from_args\n    value = self._read_variable_op()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 728, in _read_variable_op\n    self._dtype)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 550, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable global_step from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/global_step)\n\t [[node global_step/Read/ReadVariableOp (defined at <ipython-input-4-76a7a9e69621>:3) ]]\n"
     ]
    }
   ],
   "source": [
    "tmp = tf.constant([[[1,2,3,4], [5,6,7,8]]])\n",
    "\n",
    "def loss_function(pred, real):\n",
    "    \"\"\"\n",
    "    Since the target sequences are padded,\n",
    "    it is important to apply a padding mask when calculating the loss.\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=real)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)    \n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative log likelihood loss. It is useful to train a classification problem with `C` classes.\n",
    "\n",
    "Computes sparse softmax cross entropy between `logits` and `labels`. Measures the probability error in discrete classification tasks in which the\n",
    "  classes are mutually exclusive (each entry is in exactly one class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "print(session.run(tf.global_variables_initializer()))\n",
    "print(session.run(tf.report_uninitialized_variables()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [2 1 0]]\n",
      "[[[0.93333334 0.03333334 0.03333334]\n",
      "  [0.03333334 0.93333334 0.03333334]\n",
      "  [0.93333334 0.03333334 0.03333334]]\n",
      "\n",
      " [[0.03333334 0.03333334 0.93333334]\n",
      "  [0.03333334 0.93333334 0.03333334]\n",
      "  [0.93333334 0.03333334 0.03333334]]]\n",
      "(2, 3)\n",
      "13.498105\n"
     ]
    }
   ],
   "source": [
    "from ops.regularization import label_smoothing\n",
    "\n",
    "\n",
    "ids = tf.constant([[0, 1, 0], [2, 1, 0]])\n",
    "\n",
    "lgts = tf.constant([[[12.2, 20.2, 23.3], [2.2, 4.2, 12.1], [2.2, 4.2, 12.1]], [[10.1, 42.1, 24.1], [2.1, 5.1, 10.1], [10.1, 42.1, 24.1]]])\n",
    "\n",
    "smooth_labels = label_smoothing(tf.one_hot(ids, depth=3))\n",
    "\n",
    "\n",
    "# use right shifted target\n",
    "lss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=lgts, labels=smooth_labels)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(ids))\n",
    "    print(sess.run(smooth_labels))\n",
    "    print(sess.run(lss).shape)\n",
    "    print(sess.run(tf.reduce_mean(lss)))\n",
    "        \n",
    "#     print(sess.run())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.bert import BertLayer\n",
    "\n",
    "\n",
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom Keras layer, integrating BERT from tf-hub\n",
    "    \"\"\"\n",
    "    def __init__(self, url, seq_len=512, d_embedding=768, n_fine_tune_layers=None, **kwargs):\n",
    "        self.url = url\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.seq_len = seq_len\n",
    "        self.d_embedding = d_embedding\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.url,\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_bert_module\".format(self.name)\n",
    "        )\n",
    "\n",
    "        trainable_vars = self.bert.variables\n",
    "        \n",
    "        if self.trainable:\n",
    "\n",
    "            # Remove unused layers\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "\n",
    "            # Select how many layers to fine tune\n",
    "            trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "\n",
    "            # Add to trainable weights\n",
    "            for var in trainable_vars:\n",
    "                self._trainable_weights.append(var)\n",
    "\n",
    "            for var in self.bert.variables:\n",
    "                if var not in self._trainable_weights:\n",
    "                    self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        \n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        \n",
    "        bert_inputs = dict(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\"sequence_output\"]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        raise ValueError()\n",
    "        return (input_shape[0], self.seq_len, self.d_embedding)\n",
    "\n",
    "    \n",
    "    \n",
    "in_id = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"input_ids\")\n",
    "in_mask = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"input_masks\")\n",
    "in_segment = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"segment_ids\")\n",
    "\n",
    "bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "bert = BertLayer(BERT_MODEL_URL, trainable=False)(bert_inputs)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=bert_inputs, outputs=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmp1 = np.zeros((30522))\n",
    "atmp1[10] = 1\n",
    "\n",
    "atmp2 = np.zeros((30522))\n",
    "atmp2[20] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atmp = np.array([atmp1, atmp2], dtype=np.float32)\n",
    "atmp.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.initializers import Constant\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    initialize_vars(sess)\n",
    "    embedding_matrix = sess.run(bert.variable_map['bert/embeddings/word_embeddings'])\n",
    "\n",
    "target_vocab_size = len(data)\n",
    "d_model = 768\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(target_vocab_size, d_model, trainable=False, embeddings_initializer=Constant(embedding_matrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(10), Dimension(30522), Dimension(768)])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.compute_output_shape((10, target_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_20:0\", shape=(2, 30522), dtype=float32)\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Resource localhost/embedding_5/embeddings/N10tensorflow3VarE does not exist.\n\t [[node embedding_5/embedding_lookup (defined at <ipython-input-52-fac9b5b8d76d>:6) ]]\n\nCaused by op 'embedding_5/embedding_lookup', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-fac9b5b8d76d>\", line 6, in <module>\n    print(sess.run(embedding(atmp_)).shape)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/embeddings.py\", line 179, in call\n    out = embedding_ops.embedding_lookup(self.embeddings, inputs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 316, in embedding_lookup\n    transform_fn=None)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 3271, in gather\n    return params.sparse_read(indices, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 759, in sparse_read\n    self._handle, indices, dtype=self._dtype, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 633, in resource_gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Resource localhost/embedding_5/embeddings/N10tensorflow3VarE does not exist.\n\t [[node embedding_5/embedding_lookup (defined at <ipython-input-52-fac9b5b8d76d>:6) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Resource localhost/embedding_5/embeddings/N10tensorflow3VarE does not exist.\n\t [[{{node embedding_5/embedding_lookup}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-fac9b5b8d76d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0matmp_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matmp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matmp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bert/embeddings/word_embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Resource localhost/embedding_5/embeddings/N10tensorflow3VarE does not exist.\n\t [[node embedding_5/embedding_lookup (defined at <ipython-input-52-fac9b5b8d76d>:6) ]]\n\nCaused by op 'embedding_5/embedding_lookup', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-fac9b5b8d76d>\", line 6, in <module>\n    print(sess.run(embedding(atmp_)).shape)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/embeddings.py\", line 179, in call\n    out = embedding_ops.embedding_lookup(self.embeddings, inputs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 316, in embedding_lookup\n    transform_fn=None)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 3271, in gather\n    return params.sparse_read(indices, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 759, in sparse_read\n    self._handle, indices, dtype=self._dtype, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 633, in resource_gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Resource localhost/embedding_5/embeddings/N10tensorflow3VarE does not exist.\n\t [[node embedding_5/embedding_lookup (defined at <ipython-input-52-fac9b5b8d76d>:6) ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    initialize_vars(sess) \n",
    "    atmp_ = tf.convert_to_tensor(atmp, np.float32)\n",
    "    print(atmp_)\n",
    "    print(sess.run(embedding(atmp_)).shape)\n",
    "    raise ValueError\n",
    "    print(sess.run(tf.matmul(atmp, bert.variable_map['bert/embeddings/word_embeddings'])))\n",
    "    print(sess.run(bert.variable_map['bert/embeddings/word_embeddings'](np.array([0, 1]))))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512) (1, 512) (1, 512)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-368a1b3e12eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     print(x0, '\\n', x1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     print(sess.run(tmp2))  # (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)\n",
    "    initialize_vars(sess)    \n",
    "    tmp = sess.run(el)\n",
    "    x0, x1, x2, y0, y1, y2 = tmp\n",
    "    print(x0.shape, x1.shape, x2.shape)\n",
    "#     print(x0, '\\n', x1)\n",
    "    tmp2 = model.predict([x0, x1, x2])\n",
    "    print(tmp2)\n",
    "#     print(sess.run(tmp2))  # (batch_size, input_seq_len, d_model)    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.49737298  0.5550515  -0.13341121 ... -0.5284789  -0.61509997\n",
      "   -0.04155324]\n",
      "  [ 0.5157517   0.5635947  -0.09799525 ... -0.5260042  -0.62772596\n",
      "   -0.03477238]\n",
      "  [ 0.53440964  0.5700865  -0.05099516 ... -0.5282975  -0.63185966\n",
      "   -0.02259888]\n",
      "  ...\n",
      "  [ 0.39933348  0.4695823  -0.19357261 ... -0.49450147 -0.70106435\n",
      "   -0.01530197]\n",
      "  [ 0.41170758  0.47419053 -0.20090303 ... -0.5092494  -0.7242769\n",
      "    0.0037366 ]\n",
      "  [ 0.42569858  0.49202585 -0.1921086  ... -0.52926743 -0.73894566\n",
      "    0.00663666]]\n",
      "\n",
      " [[ 0.49737298  0.5550515  -0.13341121 ... -0.5284789  -0.61509997\n",
      "   -0.04155324]\n",
      "  [ 0.5157517   0.5635947  -0.09799525 ... -0.5260042  -0.62772596\n",
      "   -0.03477238]\n",
      "  [ 0.53440964  0.5700865  -0.05099516 ... -0.5282975  -0.63185966\n",
      "   -0.02259888]\n",
      "  ...\n",
      "  [ 0.39933348  0.4695823  -0.19357261 ... -0.49450147 -0.70106435\n",
      "   -0.01530197]\n",
      "  [ 0.41170758  0.47419053 -0.20090303 ... -0.5092494  -0.7242769\n",
      "    0.0037366 ]\n",
      "  [ 0.42569858  0.49202585 -0.1921086  ... -0.52926743 -0.73894566\n",
      "    0.00663666]]\n",
      "\n",
      " [[ 0.49737298  0.5550515  -0.13341121 ... -0.5284789  -0.61509997\n",
      "   -0.04155324]\n",
      "  [ 0.5157517   0.5635947  -0.09799525 ... -0.5260042  -0.62772596\n",
      "   -0.03477238]\n",
      "  [ 0.53440964  0.5700865  -0.05099516 ... -0.5282975  -0.63185966\n",
      "   -0.02259888]\n",
      "  ...\n",
      "  [ 0.39933348  0.4695823  -0.19357261 ... -0.49450147 -0.70106435\n",
      "   -0.01530197]\n",
      "  [ 0.41170758  0.47419053 -0.20090303 ... -0.5092494  -0.7242769\n",
      "    0.0037366 ]\n",
      "  [ 0.42569858  0.49202585 -0.1921086  ... -0.52926743 -0.73894566\n",
      "    0.00663666]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.49737298  0.5550515  -0.13341121 ... -0.5284789  -0.61509997\n",
      "   -0.04155324]\n",
      "  [ 0.5157517   0.5635947  -0.09799525 ... -0.5260042  -0.62772596\n",
      "   -0.03477238]\n",
      "  [ 0.53440964  0.5700865  -0.05099516 ... -0.5282975  -0.63185966\n",
      "   -0.02259888]\n",
      "  ...\n",
      "  [ 0.39933348  0.4695823  -0.19357261 ... -0.49450147 -0.70106435\n",
      "   -0.01530197]\n",
      "  [ 0.41170758  0.47419053 -0.20090303 ... -0.5092494  -0.7242769\n",
      "    0.0037366 ]\n",
      "  [ 0.42569858  0.49202585 -0.1921086  ... -0.52926743 -0.73894566\n",
      "    0.00663666]]\n",
      "\n",
      " [[ 0.49737298  0.5550515  -0.13341121 ... -0.5284789  -0.61509997\n",
      "   -0.04155324]\n",
      "  [ 0.5157517   0.5635947  -0.09799525 ... -0.5260042  -0.62772596\n",
      "   -0.03477238]\n",
      "  [ 0.53440964  0.5700865  -0.05099516 ... -0.5282975  -0.63185966\n",
      "   -0.02259888]\n",
      "  ...\n",
      "  [ 0.39933348  0.4695823  -0.19357261 ... -0.49450147 -0.70106435\n",
      "   -0.01530197]\n",
      "  [ 0.41170758  0.47419053 -0.20090303 ... -0.5092494  -0.7242769\n",
      "    0.0037366 ]\n",
      "  [ 0.42569858  0.49202585 -0.1921086  ... -0.52926743 -0.73894566\n",
      "    0.00663666]]\n",
      "\n",
      " [[ 0.49737298  0.5550515  -0.13341121 ... -0.5284789  -0.61509997\n",
      "   -0.04155324]\n",
      "  [ 0.5157517   0.5635947  -0.09799525 ... -0.5260042  -0.62772596\n",
      "   -0.03477238]\n",
      "  [ 0.53440964  0.5700865  -0.05099516 ... -0.5282975  -0.63185966\n",
      "   -0.02259888]\n",
      "  ...\n",
      "  [ 0.39933348  0.4695823  -0.19357261 ... -0.49450147 -0.70106435\n",
      "   -0.01530197]\n",
      "  [ 0.41170758  0.47419053 -0.20090303 ... -0.5092494  -0.7242769\n",
      "    0.0037366 ]\n",
      "  [ 0.42569858  0.49202585 -0.1921086  ... -0.52926743 -0.73894566\n",
      "    0.00663666]]]\n"
     ]
    }
   ],
   "source": [
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "#     sess.run(iter.initializer)\n",
    "#     tmp = sess.run(el)\n",
    "#     print(tmp)\n",
    "    sample_transformer = Transformer(\n",
    "        num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "        input_vocab_size=8500, target_vocab_size=8000)\n",
    "\n",
    "    temp_input = tf.random.uniform((64, 62))\n",
    "    temp_target = tf.random.uniform((64, 26))\n",
    "\n",
    "    fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                                   enc_padding_mask=None, \n",
    "                                   look_ahead_mask=None,\n",
    "                                   dec_padding_mask=None)\n",
    "    initialize_vars(sess)\n",
    "    \n",
    "    print(sess.run(fn_out))  # (batch_size, input_seq_len, d_model)    \n",
    "#     x0, x1, x2, y0, y1, y2 = tmp\n",
    "#     tmp2 = model.predict([x0, x1, x2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8568d044b116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# so their values get averaged.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtemp_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (3, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8568d044b116>\u001b[0m in \u001b[0;36mprint_out\u001b[0;34m(q, k, v)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtemp_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Attention weights are:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Output is:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5165\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5167\u001b[0;31m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[1;32m   5168\u001b[0m                        \u001b[0;34m\"session is registered. Use `with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5169\u001b[0m                        \u001b[0;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(q, k, v, None)\n",
    "    print ('Attention weights are:')\n",
    "    print (temp_attn.eval())\n",
    "    print ('Output is:')\n",
    "    print (temp_out.eval())\n",
    "\n",
    "    \n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiHeadAttention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3149abf8f150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_mha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, encoder_sequence, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_mha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultiHeadAttention' is not defined"
     ]
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "print(out.shape, attn.shape)\n",
    "\n",
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(26), Dimension(8000)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 62))\n",
    "temp_target = tf.random.uniform((64, 26))\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.keras.optimizers' has no attribute 'schedules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a3099a9cd8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomSchedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mUse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mAdam\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0mlearning\u001b[0m \u001b[0mrate\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0maccording\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.keras.optimizers' has no attribute 'schedules'"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    Use the Adam optimizer with a custom learning rate scheduler according to the formula\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse_categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-22b0ad8ea901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sparse_categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'"
     ]
    }
   ],
   "source": [
    "loss_object = tf.keras.losses.sparse_categorical_crossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    \"\"\"\n",
    "    Since the target sequences are padded, it is important to apply a padding mask when calculating the loss.\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 511)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0[:, :-1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(64), Dimension(26), Dimension(512)]),\n",
       " TensorShape([Dimension(64), Dimension(8), Dimension(26), Dimension(62)]),\n",
       " TensorShape([Dimension(64), Dimension(8), Dimension(26), Dimension(26)]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000)\n",
    "\n",
    "output, attn = sample_decoder(tf.random.uniform((64, 26)), \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False, look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape, attn['decoder_layer2_block1'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500)\n",
    "\n",
    "sample_encoder_output = sample_encoder(tf.random.uniform((64, 62)), \n",
    "                                       training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(50), Dimension(512)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0523 12:59:35.651068 140526081922880 saver.py:1489] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "in_id = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"input_ids\")\n",
    "in_mask = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"input_masks\")\n",
    "in_segment = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"segment_ids\")\n",
    "\n",
    "bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "bert = BertLayer(BERT_MODEL_URL, trainable=False)(bert_inputs)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=bert_inputs, outputs=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    \"\"\"\n",
    "    Mask all the pad tokens in the batch of sequence.\n",
    "    It ensures that the model does not treat padding as the input.\n",
    "    The mask indicates where pad value 0 is present:\n",
    "    it outputs a 1 at those locations, and a 0 otherwise.    \n",
    "    \"\"\"\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions so that we can add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    \"\"\"\n",
    "    The look-ahead mask is used to mask the future tokens in a sequence.\n",
    "    In other words, the mask indicates which entries should not be used. \n",
    "\n",
    "    This means that to predict the third word, only the first and second word will be used.\n",
    "    Similarly to predict the fourth word, only the first, second and the third word will be used and so on.\n",
    "    \"\"\"\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(create_padding_mask(x)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'strided_slice_9:0' shape=(1, 1, 1, 512) dtype=float32>,\n",
       " <tf.Tensor 'Maximum_1:0' shape=(1, 1, 512, 512) dtype=float32>,\n",
       " <tf.Tensor 'strided_slice_10:0' shape=(1, 1, 1, 512) dtype=float32>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_masks(x0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2028,  1997,  3725,  1005,  1055,  2087,  6450,  2406,\n",
       "         5014,  2038,  2908,  2006,  1996,  3006,  1011,  1998,  2009,\n",
       "         2428,  2003,  4906,  2005,  1037,  3035,  1012,  1996,  3694,\n",
       "         1045,  3205,  2026, 13629,  2380,  1010,  2275,  1999,  1037,\n",
       "         1015,  1010,  8380,  1011,  7456,  3776,  1010,  2038,  1037,\n",
       "         2157,  2548,  3976,  6415,  1011,  1037, 22771, 14534,  2629,\n",
       "         2213,  1012,  2021,  1996,  3776,  6074,  8304,  1996,  5096,\n",
       "         2360,  2045,  2003,  2053, 15843,  1997,  4022, 17394,  5782,\n",
       "         2000,  3193,  1996,  3200,  1012,  2188,  4906,  2005, 16664,\n",
       "         1024,  2026, 13629,  2380,  2003,  3694,  1045,  3205,  1998,\n",
       "         2001,  3294, 10601,  2058,  1037,  2093,  2095,  2622,  2011,\n",
       "         1996,  2783,  5608,  1012,  1996,  3035,  2218,  1037, 12695,\n",
       "         2182,  1999,  3541, 21136,  7430,  2005,  1017,  1010,  2199,\n",
       "         6368,  1999,  2494,  1012,  2009,  2003,  2028,  1997,  3725,\n",
       "         1005,  1055,  2087,  6450,  2406,  5014,  1998,  2038,  2908,\n",
       "         2006,  1996,  3006,  2005, 14534,  2629, 19912,  3258,  1012,\n",
       "         7010,  5226,  1010,  1996,  8228,  4944,  1010, 14105,  1996,\n",
       "         6418,  2164,  1996,  3829,  1998,  2817,  5331,  2007,  2797,\n",
       "        17692,  3871,  1012,  1520,  1996,  2332,  1521,  1055,  2534,\n",
       "         2001,  2649,  2011, 24794,  2271, 21877, 15088,  3678,  1006,\n",
       "         6549,  5272,  1007,  2004,  1005,  1996, 10418,  2282,  1999,\n",
       "        21136,  7430,  1005,  1010,  1998,  2038,  6565,  5894,  7535,\n",
       "         1998,  9487, 15673,  2147,  1012,  2009,  3138,  2039,  1037,\n",
       "         2312, 10817,  1997,  1996,  2160,  1012,  3205,  1024,  1996,\n",
       "         2160,  2038,  2260, 18390,  1010,  2184,  1997,  2068,  4372,\n",
       "        28880,  2229,  1010,  1037,  5059,  2282,  1010,  3075,  1010,\n",
       "         2817,  1998,  2851,  2282,  1012,  1996, 22445,  3040,  5010,\n",
       "         2038,  2048, 11225,  4734,  1010,  5723,  1998,  6457,  1012,\n",
       "         2110,  2135,  1024,  1996,  3776,  6074,  8304,  1996,  5096,\n",
       "         2360,  2045,  2003,  2053, 15843,  1997,  4022, 17634,  1012,\n",
       "         1996,  3668,  3829,  2003,  1037,  6919,  2155,  2686,  2007,\n",
       "         7759,  1998,  3564,  2181,  2007,  2341,  2041,  2000,  1996,\n",
       "         3871,  1012,  1998,  1996,  8546,  2778,  2064,  2202,  2039,\n",
       "         2000,  2176,  2847,  2138,  2045,  1005,  1055,  2061,  2172,\n",
       "         2000,  2156,  1012,  1996,  3035,  2218,  1037, 12695,  2012,\n",
       "         1996,  3200,  1999,  3541, 21136,  7430,  2005,  1017,  1010,\n",
       "         2199,  6368,  1012, 14675, 10239,  1010,  2132,  1997,  8623,\n",
       "         1998,  8707,  2005,  5000,  3581,  3776,  6074,  1010,  2056,\n",
       "         1024,  1005,  2009,  2003,  1037,  4310,  3200,  1010,  2028,\n",
       "         1997,  1996, 10418,  5973,  1999,  1996,  2406,  1012,  1005,\n",
       "         2057,  2024,  2893,  3037,  2013,  2248,  7846,  1010,  2013,\n",
       "         2789,  2885,  1998,  2060,  3033,  1997,  1996,  2088,  1012,\n",
       "         1005,  1996,  7759,  2282, 14567,  2049,  2434,  5997,  2989,\n",
       "         1010,  2038,  1037, 13788,  2012,  2593,  2203,  1998,  2052,\n",
       "        18579,  2835,  2012,  2560,  2484,  2111,  1012,  1996,  8546,\n",
       "         2778,  1997,  1996,  2160,  2064,  2202,  2039,  2000,  2176,\n",
       "         2847,  2138,  2045,  1005,  1055,  2061,  2172,  2000,  2156,\n",
       "         1012,  1996,  5059,  2282,  1010,  2125,  1996,  2307,  2534,\n",
       "         1010,  2003,  2028,  1997,  1996,  2116, 14036,  7258,  1999,\n",
       "         1996,  2160,  1012,  2026, 13629,  2380,  5246,  2067,  2000,\n",
       "        11502,  2692,  1998,  2001,  2320,  1996,  2188,  1997,  4787,\n",
       "         1052,  6672,  1010,  4905,  1011,  2236,  2000,  2798,  1045,\n",
       "         1012,  1996,  3075,  2282, 15646,  5328,  2058,  1996,  4193,\n",
       "        10833,  1012,  2021,  1996,  2160,  2036,  2038,  2260, 18390,\n",
       "         1010,  2184,  1997,  2068,  4372, 28880,  2229,  1010,  1037,\n",
       "         5059,  2282,  1010,  3075,  1010,  2817,  1010,  2851,  2282,\n",
       "         1010,  3021, 14619,  2282,  1010,  2399,  2282]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 14:56:33.385675 139957305521984 dataset_builder.py:177] Load pre-computed datasetinfo (eg: splits) from bucket.\n",
      "I0528 14:56:33.650062 139957305521984 dataset_info.py:377] Loading info from GCS for ted_hrlr_translate/pt_to_en/0.0.1\n",
      "I0528 14:56:34.125548 139957305521984 dataset_builder.py:236] Generating dataset ted_hrlr_translate (/home/ec2-user/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset ted_hrlr_translate (124.94 MiB) to /home/ec2-user/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6dfc945abf4e8db29e012e3edf59f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Completed...', max=1, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322f001684f943b5a4bd96f385d9e393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Size...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2754661cd1404eab89a209a68c687e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Extraction completed...', max=1, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 14:56:34.203127 139957305521984 download_manager.py:241] Downloading http://www.phontron.com/data/qi18naacl-dataset.tar.gz into /home/ec2-user/tensorflow_datasets/downloads/phontron.com_qi18naacl-datasetLVhDyvf9PQ-GjP4jim31ESZuvRjHI5wpNhR5SJvsNOo.tar.gz.tmp.85acbe6968a948c0ab60989f292e5947...\n",
      "I0528 14:56:46.151685 139957305521984 dataset_builder.py:675] Generating split train\n",
      "I0528 14:56:46.155997 139957305521984 file_format_adapter.py:271] Writing TFRecords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20690b6bc9b14ea0aff1cd5ab3ec079d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae1406d2d9f4c42ba3b338d142995b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Shuffling...', max=1, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_datasets/core/file_format_adapter.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 14:56:52.763825 139957305521984 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_datasets/core/file_format_adapter.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5442f9e3b56a46f0b06531ab15857bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1718689923304bb088ae2ca70a42626b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=51785, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 14:56:53.236819 139957305521984 dataset_builder.py:675] Generating split validation\n",
      "I0528 14:56:53.238343 139957305521984 file_format_adapter.py:271] Writing TFRecords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5001f59ee4244472828d2bde386ec544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8832b4d6042745e9b86586920bac8ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Shuffling...', max=1, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2477f8c0d1774825bc5e3450f2268e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fe350d7e8b45cf9bfac83446af7abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=1193, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 14:56:53.504857 139957305521984 dataset_builder.py:675] Generating split test\n",
      "I0528 14:56:53.506487 139957305521984 file_format_adapter.py:271] Writing TFRecords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4168a25eb07a4d5a9cc12e37115ac347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6556ab0e53a4233a9a486272b8af817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Shuffling...', max=1, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccf568f988e4526b750fbfafb87b076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38273357a0624326b45f6552b97f96e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=1803, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 14:56:53.876027 139957305521984 dataset_builder.py:264] Skipping computing stats for mode ComputeStatsMode.AUTO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset ted_hrlr_translate downloaded and prepared to /home/ec2-user/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
    "\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os astrónomos acreditam que cada estrela da galáxia tem um planeta , e especulam que até um quinto deles tem um planeta do tipo da terra que poderá ter vida , mas ainda não vimos nenhum deles .\n",
      "\n",
      "astronomers now believe that every star in the galaxy has a planet , and they speculate that up to one fifth of them have an earth-like planet that might be able to harbor life , but we have n't seen any of them .\n"
     ]
    }
   ],
   "source": [
    "iter = train_examples.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)  \n",
    "    x, y = sess.run(el)\n",
    "    print(x.decode('utf-8'))\n",
    "    print()\n",
    "    print(y.decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
